name: LLM-Logger-v1
type: feature
description: ""
parameters: []
endpointFlows:
  - name: PreFlow
    mode: Response
    steps:
      - name: ML-Contents0
        condition: contents_0 != null and contents_0 != ""
      - name: ML-Contents1
        condition: prompt_contents_1 != null and prompt_contents_1 != ""
      - name: ML-Contents2
        condition: prompt_contents_2 != null and prompt_contents_2 != ""
      - name: ML-Contents3
        condition: prompt_contents_3 != null and prompt_contents_3 != ""
      - name: ML-Contents4
        condition: prompt_contents_4 != null and prompt_contents_4 != ""
targetFlows: []
endpoints: []
targets: []
policies:
  - name: ML-Contents0
    type: MessageLogging
    content:
      MessageLogging:
        _attributes:
          continueOnError: "false"
          enabled: "true"
          name: ML-Contents0
        DisplayName:
          _text: ML-Contents0
        CloudLogging:
          LogName:
            _text: projects/{organization.name}/logs/apigee-llm
          Message:
            _attributes:
              contentType: application/json
            _text: '{"proxyName":"{apiproxy.name}","llmLogType":"{log_type}","segment":"0","messageid":"{messageid}","content":"{contents_0}"}'
  - name: ML-Contents1
    type: MessageLogging
    content:
      MessageLogging:
        _attributes:
          continueOnError: "false"
          enabled: "true"
          name: ML-Contents1
        DisplayName:
          _text: ML-Contents1
        CloudLogging:
          LogName:
            _text: projects/{organization.name}/logs/apigee-llm
          Message:
            _attributes:
              contentType: application/json
            _text: '{"proxyName":"{apiproxy.name}","llmLogType":"{log_type}","segment":"1","messageid":"{messageid}","content":"{contents_1}"}'
  - name: ML-Contents2
    type: MessageLogging
    content:
      MessageLogging:
        _attributes:
          continueOnError: "false"
          enabled: "true"
          name: ML-Contents2
        DisplayName:
          _text: ML-Contents2
        CloudLogging:
          LogName:
            _text: projects/{organization.name}/logs/apigee-llm
          Message:
            _attributes:
              contentType: application/json
            _text: '{"proxyName":"{apiproxy.name}","llmLogType":"{log_type}","segment":"2","messageid":"{messageid}","content":"{contents_2}"}'
  - name: ML-Contents3
    type: MessageLogging
    content:
      MessageLogging:
        _attributes:
          continueOnError: "false"
          enabled: "true"
          name: ML-Contents3
        DisplayName:
          _text: ML-Contents3
        CloudLogging:
          LogName:
            _text: projects/{organization.name}/logs/apigee-llm
          Message:
            _attributes:
              contentType: application/json
            _text: '{"proxyName":"{apiproxy.name}","llmLogType":"{log_type}","segment":"3","messageid":"{messageid}","content":"{contents_3}"}'
  - name: ML-Contents4
    type: MessageLogging
    content:
      MessageLogging:
        _attributes:
          continueOnError: "false"
          enabled: "true"
          name: ML-Contents4
        DisplayName:
          _text: ML-Contents4
        CloudLogging:
          LogName:
            _text: projects/{organization.name}/logs/apigee-llm
          Message:
            _attributes:
              contentType: application/json
            _text: '{"proxyName":"{apiproxy.name}","llmLogType":"{log_type}","segment":"4","messageid":"{messageid}","content":"{contents_4}"}'
resources: []
