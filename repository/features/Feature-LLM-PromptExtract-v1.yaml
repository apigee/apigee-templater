name: Feature-LLM-PromptExtract-v1
type: feature
description: |
  This feature tries to extract the last user prompt from both gemini as well as openapi prompt formats.

  ## Prerequisites
  None.

  ## Inputs
  - User prompts are checked in both the contents.parts (gemini) and messages.content (openapi) structures.

  ## Outputs
  - If a prompt is found, it is written to the Apigee variable **llm.promptInput**.
  - If a prompt is found, the estimated token length is written to the Apigee variable **llm.promptEstimatedTokenCount**.
priority: 10
parameters: []
endpointFlows:
  - name: PreFlow
    mode: Request
    steps:
      - name: JS-EstimateTokens
targetFlows: []
endpoints: []
targets: []
policies:
  - name: JS-EstimateTokens
    type: Javascript
    content:
      Javascript:
        _attributes:
          continueOnError: "false"
          enabled: "true"
          timeLimit: "200"
          name: JS-EstimateTokens
        DisplayName:
          _text: JS-EstimateTokens
        Properties: {}
        ResourceURL:
          _text: jsc://estimate-tokens.js
resources:
  - name: estimate-tokens.js
    type: jsc
    content: |-
      var promptInput = "";
      var requestObject = request.content.asJSON;

      if (requestObject) {
        promptInput = getLastPrompt(requestObject);
      }

      context.setVariable("llm.promptInput", promptInput);
      if (promptInput) {
        var word_count = promptInput.split(" ").length;
        var char_count = promptInput.length;

        var tokens_count_word_est = word_count / 0.75;
        var tokens_count_char_est = char_count / 4.0;

        var result = 0;

        if (tokens_count_word_est > tokens_count_char_est)
          result = tokens_count_word_est;
        else if (tokens_count_char_est > tokens_count_word_est)
          result = tokens_count_word_est;

        context.setVariable("llm.promptEstimatedTokenCount", result);
        context.setVariable("quota.weight", result);
      }

      function getLastPrompt(requestObject) {
        var promptInput = "";
        if (requestObject && requestObject["contents"]) {
          // gemini format
          var userConversations = requestObject.contents.filter(item => item.role === 'user');
          if (userConversations.length > 0) {
            var lastUserConversation = userConversations[userConversations.length - 1];
            if (lastUserConversation && lastUserConversation.parts && lastUserConversation.parts.length > 0)
              promptInput = lastUserConversation.parts[lastUserConversation.parts.length - 1].text;
          }
        } else if (requestObject && requestObject["messages"]) {
          // openapi format
          var userConversations = requestObject.messages.filter(item => item.role === 'user');
          if (userConversations && userConversations.length > 0) {
            print("found conversations!");
            var lastUserConversation = userConversations[userConversations.length - 1];
            if (lastUserConversation.content && Array.isArray(lastUserConversation.content) && lastUserConversation.content.length > 0) {
              // array of content
              print("found array of content!");
              const contentTexts = lastUserConversation.content.filter(item => item.type === 'text');
              if (contentTexts && contentTexts.length > 0) {
                promptInput = contentTexts[contentTexts.length - 1].text;
              }
            } else if (lastUserConversation.content) {
              promptInput = lastUserConversation.content;
            }
          }
        }

        return promptInput;
      }

      function setLastPrompt(requestObject, promptInput) {
        if (requestObject && requestObject["contents"]) {
          // gemini format
          var userConversations = requestObject.contents.filter(item => item.role === 'user');
          if (userConversations.length > 0) {
            var lastUserConversation = userConversations[userConversations.length - 1];
            if (lastUserConversation && lastUserConversation.parts && lastUserConversation.parts.length > 0)
              lastUserConversation.parts[lastUserConversation.parts.length - 1].text = promptInput;
          }
        } else if (requestObject && requestObject["messages"]) {
          // openapi format
          var userConversations = requestObject.messages.filter(item => item.role === 'user');
          if (userConversations && userConversations.length > 0) {
            var lastUserConversation = userConversations[userConversations.length - 1];
            if (lastUserConversation.content && lastUserConversation.content.length && lastUserConversation.content.length > 0) {
              // array of content
              const contentTexts = lastUserConversation.content.filter(item => item.type === 'text');
              if (contentTexts && contentTexts.length > 0)
                contentTexts[contentTexts.length - 1].text = promptInput;
            } else if (lastUserConversation.content) {
              lastUserConversation.content = promptInput;
            }
          }
        }

        return requestObject;
      }
tests:
  - request: '{"messages": [{"role": "user", "content": "why is the sky blue?"}]}'
    assertions:
      - llm.promptInput==="why is the sky blue?"
      - llm.promptEstimatedTokenCount===6.666666666666667
  - request: '{"messages": [{"role": "user", "content": [{"type": "text", "text":
      "why is the sky blue?"}]}]}'
    assertions:
      - llm.promptInput==="why is the sky blue?"
      - llm.promptEstimatedTokenCount===6.666666666666667
