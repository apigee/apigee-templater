name: Feature-LLM-DataCollector-v1
type: proxy
description: Proxy for Feature-LLM-DataCollector-v1
parameters: []
endpoints:
  - name: default
    basePath: /feature-llm-tokencounts
    routes:
      - name: default
    flows:
      - name: PostFlow
        mode: Response
        steps:
          - name: DC-ModelInfo
    faultRules: []
targets: []
policies:
  - name: DC-ModelInfo
    type: DataCapture
    content:
      DataCapture:
        _attributes:
          name: DC-ModelInfo
          continueOnError: "false"
          enabled: "true"
        DisplayName:
          _text: DC-ModelInfo
        IgnoreUnresolvedVariables:
          _text: "true"
        Capture:
          - Collect:
              _attributes:
                ref: llm.model
                default: ""
            DataCollector:
              _text: llm_model
          - Collect:
              _attributes:
                ref: llm.promptTokenCount
                default: "0"
            DataCollector:
              _text: llm_prompt_token_count
          - Collect:
              _attributes:
                ref: llm.responseTokenCount
                default: "0"
            DataCollector:
              _text: llm_response_token_count
          - Collect:
              _attributes:
                ref: llm.totalTokenCount
                default: "0"
            DataCollector:
              _text: llm_total_token_count
resources: []
