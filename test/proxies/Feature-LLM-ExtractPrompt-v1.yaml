name: Feature-LLM-ExtractPrompt-v1
type: proxy
description: "Proxy for Feature-LLM-ExtractPrompt-v1"
parameters: []
endpoints:
  - name: default
    basePath: /feature-llm-extractprompt-v1
    routes:
      - name: default
    flows:
      - name: PreFlow
        mode: Request
        steps:
          - name: JS-ExtractPrompt
    faultRules: []
targets: []
policies:
  - name: JS-ExtractPrompt
    type: Javascript
    content:
      Javascript:
        _attributes:
          continueOnError: "false"
          enabled: "true"
          timeLimit: "200"
          name: JS-ExtractPrompt
        DisplayName:
          _text: JS-ExtractPrompt
        Properties: {}
        ResourceURL:
          _text: jsc://ExtractPrompt.js
resources:
  - name: ExtractPrompt.js
    type: jsc
    content: >-
      var requestObj = request.content.asJSON;

      print("json: "+ JSON.stringify(requestObj))

      context.setVariable("PROMPT_INPUT", getLatestUserText(requestObj));


      function getLatestUserText(json){
        // Find all objects in the contents array where the role is "user"
        const userConversations = json.contents.filter(item => item.role === 'user');

        // Get the last item from the filtered array
        const lastUserConversation = userConversations[userConversations.length - 1];

        // Return the text from the parts array of the last item
        return lastUserConversation.parts[lastUserConversation.parts.length -1].text;
      };
